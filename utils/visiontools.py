# -*- coding: utf-8 -*-
"""visiontools.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1LfoiYmkbwpQbAru2i6VTIgxA3XtUEAfs

# Testing for 1.
"""

# Import libraries used for visualization, image processing, I/O
import tensorflow as tf
import scipy.ndimage
import matplotlib.pyplot as plt
import numpy as np
import cv2
from urllib.request import urlopen
from PIL import Image
import io

def show_image(images, title=None, ncols=4, figsize=(15, 5)):
  # Calculate the number of rows needed for the given number of images and columns
  n_images = len(images)
  nrows = (n_images + ncols -1) // ncols

  # Create a new figure for the subplots
  plt.figure(figsize=figsize)

  # Loop over all images and display them in subplots
  for i, img in enumerate(images):
    plt.subplot(nrows, ncols, i+1)   # Create subplot at position(row, col)

    # If the image is a file path or url, load it
    if isinstance(img, str):
      img = load_image(img)

    # If it is a grayscale image with shape(H, W, 1), remove the last channel dimension
    if img.shape[-1] == 1:
      img = img.squeeze(-1)

    # Show the image
    plt.imshow(img)
    plt.axis('off')   # Hide axis ticks

    # Set the title if provided
    if titles:
      plt.title(titles[i])


  #Optimize spacing and layout
  plt.tight_layout()
  plt.show()

def draw_boxes(images, boxes, color=(255, 0, 0), thickness=2):
  """
  Draw rectangles (bounding boxes) on an image.

  Parameters:
  - image: input image (Numpy array)
  - boxes: list of tuples in format (x1, y1, x2, y2)
  - color: box color (default is red)
  - thickness: line thickness of the rectangle
  """

  img_copy = image.copy()  # Avoid modifying original image

  # Draw each box on the image using openCV
  for (x1, y1, x2, y2) in boxes:
    cv2.rectangle(img_copy, (x1, y1), (x2, y2), color, thickness)

  return img_copy  # return the image with boxes

def load_image(path_or_url):
  """
  Load an image from a local file or a URL.

  Parameters:
  - path_or_url: string, either a local path or a web URL

  Return:
  - Numpy array representing the image.
  """

  try:
    # If input start with 'http', treat it as a URL and download the image.
    if path_or_url.startswith('http'):
      with urlopen(path_or_url) as response:
        img_bytes = response.read   # read image data as bytes
        img = Image.open(io.BytesIo(img_bytes))   # open image as bytes in memory

    # Otherwise, load image from a local source
    else:
      img = Image.open(path_or_url)

    return np.array(img)   # Convert to numpy array for processing

  except Exception as e:
     print("Error loading image:", e)
     return None

def circle(size, r_shrink=1, val=1):
  """ Create a 2D image with a circle of given intensity."""
  h,w = size  # hieght and width
  y,x = np.ogrid[:h, :w]  # cordinate grid for y and x
  center_y, center_x = h//2, w//2   # Define the circle center(image center)
  radius = min(h, w)//2 - r_shrink   # Calculate radius, shrink it slightly to avoid touching edges

  # Create a bolean mask where each pixel is inside the circle
  mask = (x - center_x)**2 + (y - center_y)**2 <= radius**2
  img = np.zeros((h, w), dtype=np.float32)  # Start with a black image (all zeros)
  img[mask] = val  # set pixels inside the circle to a specified value
  return img   # Return the synthetic circle image

def random_transform(image, jitter=3, fill_method='replicate'):
  #Randomly shift the image by up to 'jitter' pixels in any direction

  # Convert TensorFlow tensor to Numpy array if needed
  if isinstance(image, tf.Tensor):
    image = image.numpy()

  # Generate a random shift in both y and x directions (+/- jitter range)
  shift = np.random.randint(-jitter, jitter +1, size=2)

  # Set the border handling mode for the shifted image
  if fill_method == 'replicate':
    mode = 'nearest'   # Replicate edge pixels
  elif fill_method == 'reflect':
    mode = 'reflect'   # Mirrors image at the border
  else:
    mode = 'constant'  # Fills border with zeros

  # Apply the shift depending on whether the image is 2D (grayscale) or 3D (e.g. RGB)
  if image.ndim == 2:
    # Apply shift directly to a single-channel image
    shifted = scipy.ndimage.shift(image, shift=shift, mode=mode)
  elif np.ndim == 3:
    # Apply separately to each channel, then stack them back togetther
    shifted = np.stack([
        scipy.ndimage.shift(image[..., c], shift=shift, mode=mode)
        for c in range(image.shape[-1])
    ], axis=-1)
  else:
    # Raise error if the image is unsupported
    raise ValueError("Unsupported image shape")

  # Convert the result back to TensorFlow tensor with float32 data type
  return tf.convert_to_tensor(shifted, dtype=tf.float32)

